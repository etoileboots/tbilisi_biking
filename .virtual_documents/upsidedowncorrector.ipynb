


# import libraries 
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Flatten, Dense, Dropout
from tensorflow.keras.applications import MobileNetV2
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import shutil
from pathlib import Path
from PIL import Image

# Upload manually identified path of upright and upside-down images (500 images each) 
dataset_path = "/Volumes/MRDALLMAYR/data/data_for_RWtraining" 
upright_folder = os.path.join(dataset_path, "R")
upside_folder = os.path.join(dataset_path, "W")

# Validate Images (sometimes they are corrupted in the downloading process from Mapillary)
def check_images(folder_path):
    print(f"Validating images in folder: {folder_path}")
    for root, _, files in os.walk(folder_path):
        for file in files:
            file_path = os.path.join(root, file)
            try:
                with Image.open(file_path) as img:
                    img.verify()  # Verify if the file is an image
            except (IOError, SyntaxError) as e:
                print(f"Problem with file: {file_path} - {e}")
                os.remove(file_path)  # Remove problematic file

# Check Images 
check_images(upright_folder)
check_images(upside_folder)

# Create Split Directories for ML training, validation, testing
split_base_dir = "/Volumes/MRDALLMAYR/data/upsidedown_identification/split_dataset"
os.makedirs(split_base_dir, exist_ok=True)

train_dir = os.path.join(split_base_dir, "train")
val_dir = os.path.join(split_base_dir, "val")
test_dir = os.path.join(split_base_dir, "test")

for split in [train_dir, val_dir, test_dir]:
    os.makedirs(os.path.join(split, "upright"), exist_ok=True)
    os.makedirs(os.path.join(split, "upside_down"), exist_ok=True)

# Step 4: Split Data
def split_and_copy_images(src_folder, train_dest, val_dest, test_dest, label):
    all_images = list(Path(src_folder).glob("*.jpg"))  # Adjust extension if not .jpg
    train_imgs, temp_imgs = train_test_split(all_images, test_size=0.3, random_state=42)
    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)

    for img in train_imgs:
        shutil.copy(img, os.path.join(train_dest, label, img.name))
    for img in val_imgs:
        shutil.copy(img, os.path.join(val_dest, label, img.name))
    for img in test_imgs:
        shutil.copy(img, os.path.join(test_dest, label, img.name))

split_and_copy_images(upright_folder, train_dir, val_dir, test_dir, "upright")
split_and_copy_images(upside_folder, train_dir, val_dir, test_dir, "upside_down")

# Step 5: Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1.0 / 255.0,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
)

val_test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode="binary",
)

val_generator = val_test_datagen.flow_from_directory(
    val_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode="binary",
    shuffle=False,
)

test_generator = val_test_datagen.flow_from_directory(
    test_dir,
    target_size=(224, 224),
    batch_size=32,
    class_mode="binary",
    shuffle=False,
)

# Step 6: Model Architecture
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False  # Freeze pre-trained layers

model = Sequential(
    [
        base_model,
        Flatten(),
        Dense(128, activation="relu"),
        Dropout(0.5),
        Dense(1, activation="sigmoid"),  # Binary classification
    ]
)

model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])

# Step 7: Model Training
history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=10,  # Adjust epochs based on your data
    verbose=1,
)

# Step 8: Evaluation on Test Set
test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy:.2f}")

# Predictions and Metrics
predictions = (model.predict(test_generator) > 0.5).astype("int32")
true_labels = test_generator.classes

print("\nClassification Report:")
print(classification_report(true_labels, predictions, target_names=test_generator.class_indices.keys()))

print("\nConfusion Matrix:")
print(confusion_matrix(true_labels, predictions))

# Step 9: Save Model
model.save("image_orientation_classifier.h5")
print("Model saved as image_orientation_classifier.h5")

# Step 10: Prediction on Unseen Data
def classify_image(image_path, model):
    from tensorflow.keras.preprocessing import image

    img = image.load_img(image_path, target_size=(224, 224))
    img_array = image.img_to_array(img) / 255.0
    img_array = np.expand_dims(img_array, axis=0)

    prediction = model.predict(img_array)
    return "Upright" if prediction >= 0.5 else "Upside-Down"


# Example Usage
image_path = "/Users/etoileboots/Downloads/111334917688345.jpg"  # Replace with your image path
result = classify_image(image_path, model)
print(f"The image is classified as: {result}")

# Optional: Plot Training History
plt.plot(history.history["accuracy"], label="Train Accuracy")
plt.plot(history.history["val_accuracy"], label="Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()


import os
import cv2
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array, load_img
from tqdm import tqdm
from pathlib import Path
import shutil

# Paths
dataset_path = "/Volumes/MRDALLMAYR/data/mapillary_images_osm"  # Replace with your dataset path
output_base_dir = "/Volumes/MRDALLMAYR/data/WR"  # Directory to save classified images
os.makedirs(output_base_dir, exist_ok=True)
"""upright_dir = os.path.join(output_base_dir, "upright")
upside_down_dir = os.path.join(output_base_dir, "upside_down")
os.makedirs(upright_dir, exist_ok=True)
os.makedirs(upside_down_dir, exist_ok=True)"""

# Sequential log file
log_file = os.path.join(output_base_dir, "classification_results.csv")
if not os.path.exists(log_file):
    pd.DataFrame(columns=["image_path", "classification"]).to_csv(log_file, index=False)

model_path = "image_orientation_classifier.h5"  # Replace with your model path
model = load_model(model_path)

# Read already processed images from the log file to avoid reprocessing
processed_images = set(pd.read_csv(log_file)["image_path"].tolist())

# Helper function to classify images
def classify_image(image_path, model):
    img = load_img(image_path, target_size=(224, 224))
    img_array = img_to_array(img) / 255.0  # Normalize the image
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    prediction = model.predict(img_array)
    return "upside_down" if prediction >= 0.5 else "upright"

# Iterate over dataset and classify images
for root, _, files in tqdm(os.walk(dataset_path), desc="Processing images"):
    for file in files:
        if file.endswith((".jpg", ".png", ".jpeg")):  # Process only image files
            image_path = os.path.join(root, file)
            if image_path in processed_images:
                continue  # Skip already processed images

            try:
                # Classify the image
                classification = classify_image(image_path, model)
                # Append results to the log file
                with open(log_file, "a") as f:
                    f.write(f"{image_path},{classification}\n")

            except Exception as e:
                print(f"Error processing {image_path}: {e}")

print(f"Classification completed. Results are being logged in {log_file}")



# Flip to be the right way around 
import pandas as pd
from PIL import Image

# Path to the CSV file
csv_path = "/Volumes/MRDALLMAYR/data/WR/classification_results.csv"  # Replace with the actual path to your CSV file

# Load the CSV file
data = pd.read_csv(csv_path, header=None, names=["image_path", "orientation"])

# Calculate percentages
total_images = len(data)
upright_count = len(data[data["orientation"] == "upright"])
upside_down_count = len(data[data["orientation"] == "upside_down"])

upright_percentage = (upright_count / total_images) * 100
upside_down_percentage = (upside_down_count / total_images) * 100

print(f"Total Images: {total_images}")
print(f"Upright Images: {upright_count} ({upright_percentage:.2f}%)")
print(f"Upside Down Images: {upside_down_count} ({upside_down_percentage:.2f}%)")

# Flip upside-down images
for _, row in data.iterrows():
    image_path = row["image_path"]
    orientation = row["orientation"]
    
    if orientation == "upside_down":
        try:
            # Open the image
            img = Image.open(image_path)
            
            # Flip the image
            flipped_img = img.rotate(180)
            
            # Overwrite the image in the same location
            flipped_img.save(image_path)
            print(f"Flipped and overwritten: {image_path}")
        except Exception as e:
            print(f"Error processing {image_path}: {e}")

print("Processing complete.")
