!pip install pyarrow


!pip install zensvi keras tensorflow census us opencv-python pandas


# Import relevant libaries
from census import Census
from us import states
import pandas as pd
import requests
import os
import geopandas as gpd
from shapely.geometry import Point
from shapely import wkt
import random
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.colors import LinearSegmentedColormap
from mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score


# Load panoptic segmentation CSV
panoptic_file_path = "/Volumes/MRDALLMAYR/data/segment_data/summary_output/panoptic_label_counts.csv"  
panoptic_data = pd.read_csv(panoptic_file_path)

# Load semantic segmentation data csv 
semantic_file_path = "/Volumes/MRDALLMAYR/data/segment_data/summary_output/semantic_pixel_ratios.csv"  
semantic_data = pd.read_csv(semantic_file_path)


panoptic_data.head()


semantic_data.head()


# Extract block_group_id into a new column from filename_key for later block-group level analysis 
panoptic_data['block_group_id'] = panoptic_data['filename_key'].str.extract(r'block_(\d+)_')[0]
semantic_data['block_group_id'] = semantic_data['filename_key'].str.extract(r'block_(\d+)_')[0]


panoptic_data.head()


semantic_data.head()
semantic_data = semantic_data.fillna(0)


# Define the entropy-based calculation function
def calculate_vc(group):
    pixel_ratios = group['pixel_ratios'].values
    pixel_ratios = pixel_ratios[pixel_ratios > 0]  # Exclude zeros or negligible values
    n = len(pixel_ratios)
    if n == 0:
        return 0  # If no valid ratios, return 0
    vc = -np.sum(pixel_ratios * np.log(pixel_ratios)) / np.log(n)
    return vc

# Calculate VC per image
vc_per_image = (
    semantic_data.groupby('filename_key')
    .apply(calculate_vc)
    .reset_index(name='VC')
)

# Add block group information for each image
vc_per_image['block_group'] = vc_per_image['filename_key'].str.extract(r'block_(\d+)_')

# Save VC per image to a CSV file
vc_per_image.to_csv('vc_per_image.csv', index=False)

# Aggregate VC by block group
vc_per_block_group = (
    vc_per_image.groupby('block_group')['VC']
    .mean()
    .reset_index(name='mean_VC')
)

# Save VC per block group to a CSV file
vc_per_block_group.to_csv('vc_per_block_group.csv', index=False)

# Display the final results
print(vc_per_image)
print(vc_per_block_group)



# Bar Chart: Visual Complexity per Block Group
import seaborn as sns
bar_color1 = "#fa8775"
bar_color2 = "#0000ff"
plt.figure(figsize=(8, 5))
sns.barplot(data=vc_per_block_group, x='block_group', y='mean_VC', color=bar_color2)
plt.title('Mean Visual Complexity per Block Group')
plt.xlabel('Block Group')
plt.ylabel('Mean Visual Complexity (VC)')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()


# Histogram: Distribution of VC Across All Images
plt.figure(figsize=(8, 5))
sns.histplot(data=vc_per_image, x='VC', bins=40, kde=True, color=bar_color2)
plt.title('Distribution of Visual Complexity (VC) Across All Images')
plt.xlabel('Visual Complexity (VC)')
plt.ylabel('Frequency')
plt.tight_layout()
plt.show()


# Merge total avg pixel ratios back into the aggregated data
total_seg_data = panoptic_data.merge(
    semantic_data, on='filename_key', how='left'
)

total_seg_data.head()


# Calculate the mean pixel ratios for each category in block groups 
mean_agg_ratios = (
    semantic_data.groupby(['block_group_id', 'label_name'])
    .agg(avg_pixels=('pixel_ratios', 'mean'))
    .reset_index()
)

mean_agg_ratios.head(10)


# Calculate the mean pixel ratios for each category in block groups 
mean_agg_labels = (
    panoptic_data.groupby(['block_group_id', 'label_name'])
    .agg(avg_counts=('label_counts', 'mean'))
    .reset_index()
)

# Aggregate label_counts for each label_name by block_group_id
sum_agg_labels = (
    panoptic_data.groupby(['block_group_id', 'label_name'])
    .agg(total_counts=('label_counts', 'sum'))
    .reset_index()
)


mean_agg_labels.head()


sum_agg_labels.head()





# Heatmap of relative pixel ratio values for block groups 
import seaborn as sns

# Create a pivot table for proportions
pivot_table = mean_agg_ratios.pivot(
    index='block_group_id', columns='label_name', values='avg_pixels'
).fillna(0)

# Plot heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(pivot_table, cmap='coolwarm', annot=False)
plt.title('Heatmap of Relative Pixel Ratio Proportions of Object Types by Block Group')
plt.xlabel('Object Types (Label Name)')
plt.ylabel('Block Group ID')
plt.show()



# Calculate relative proportions of the pixel ratios of object types within each block group
# Compute total ratios per block_group_id
total_pixel_ratios_per_group = (
    mean_agg_ratios.groupby('block_group_id')['avg_pixels'].sum().reset_index()
)
total_pixel_ratios_per_group.rename(columns={'avg_pixels': 'total_pixels'}, inplace=True)

# Merge total avg pixel ratios back into the aggregated data
total_semantic_agg = mean_agg_ratios.merge(
    total_pixel_ratios_per_group, on='block_group_id', how='left'
)

total_semantic_agg.head()


# Calculate proportions for each label_name within each block group
total_semantic_agg['relative_ratios'] = (
    total_semantic_agg['avg_pixels'] / total_semantic_agg['total_pixels']
)
total_semantic_agg.head()


# Create a stacked bar chart
pivot_table_counts = total_semantic_agg.pivot(
    index='block_group_id', columns='label_name', values='relative_ratios'
).fillna(0)

pivot_table_counts.plot(kind='bar', stacked=True, figsize=(20, 16), colormap='tab20')
plt.title('Distribution of Pixel Ratios of Object Types by Block Group')
plt.xlabel('Block Group ID')
plt.ylabel('Relative Ratios')
plt.legend(title='Object Types', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.show()






census_data = pd.read_parquet("/Volumes/MRDALLMAYR/data/census_data/census.parquet")
BG_shp_df = pd.read_csv("/Volumes/MRDALLMAYR/data/tx201bgdata.csv")
BG_census_df = pd.merge(BG_shp_df, census_data, how="left", on="GEOID20")
BG_census_df['geometry'] = BG_census_df['WKT'].apply(wkt.loads)
BG_census_gdf = gpd.GeoDataFrame(BG_census_df, geometry='geometry')

# 50 block groups for the initial analysis 
BG50_gdf = BG_census_gdf[:50]
BG50_gdf.head()



# Create the main figure with the larger map
fig, ax1 = plt.subplots(figsize=(12, 8))  # Larger main map

# Plot the full county on the main axis
BG_census_gdf.plot(ax=ax1, color='lightgrey', edgecolor='grey', alpha=0.5)
BG50_gdf.plot(ax=ax1, edgecolor='k', color="tomato")
ax1.set_title("Block Groups Harris County, Texas (2020)\nwith Chosen Large Sample")
ax1.set_xlabel("Longitude")
ax1.set_ylabel("Latitude")
plt.tight_layout()
plt.show()

# still need to analyze how many samples i actually have here...

"""# Clean data and filter
BG_census_gdf.loc[BG_census_gdf['B19013_001E'] == -666666666.0, 'B19013_001E'] = np.nan
filtered_BG_gdf = BG_census_gdf.dropna(subset=['B19013_001E'])"""


import pandas as pd
import geopandas as gpd
from shapely.geometry import Polygon

# Pivot segmentation data to create one column per object type
segmentation_pivot = total_semantic_agg.pivot(
    index="block_group_id",
    columns="label_name",
    values="relative_ratios"
).reset_index()
segmentation_pivot.head()


# Make a copy of BG50 
BG50_gdf = BG50_gdf.copy()

# Ensure no issue with merging 
segmentation_pivot.loc[:, 'block_group_id'] = segmentation_pivot['block_group_id'].astype(str)
BG50_gdf.loc[:,'GEOID20'] = BG50_gdf['GEOID20'].astype(str)
print(segmentation_pivot.head())
print(BG50_gdf.head())
# Merge census data with segmentation data
BG_census_semantic_data = pd.merge(
    BG50_gdf, 
    segmentation_pivot, 
    left_on="GEOID20", 
    right_on="block_group_id", 
    how="left"
)
print(BG_census_semantic_data.head())



# Convert merged data into a GeoDataFrame
BG_census_semantic_gdf = gpd.GeoDataFrame(BG_census_semantic_data, geometry="geometry")

# Fill Nan values as 0 
BG_census_semantic_gdf = BG_census_semantic_gdf.fillna(0)
BG_census_semantic_gdf.head()


import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt


# Identify the dominant object (column with the highest ratio) for each block group
object_columns = BG_census_semantic_gdf.columns.difference(["ALAND20", "geometry", 'AWATER20', 
                                                'B01001_001E', 'B08301_010E', 'B19013_001E', 
                                                'BLKGRPCE20', "GEOID20", "block_group_id", 
                                                'TRACTCE20', 'COUNTYFP20', 'FUNCSTAT20', 
                                                "color", 'INTPTLAT20', 'INTPTLON20', 'NAMELSAD20', 
                                                 "WKT", 'block group', 'county', 
                                                'state', 'tract', 'MTFCC20','STATEFP20'])


# Create a new column for the dominant object
BG_census_semantic_gdf["dominant_object"] = BG_census_semantic_gdf[object_columns].idxmax(axis=1)




# Create a color map for the dominant objects
unique_objects = merged_gdf["dominant_object"].unique()
print(unique_objects)
# Define custom colors for dominant objects
color_map = {
    "Road": "#123740",           # Asphalt gray, representing roads
    "Sky": "#b0d7e1",           # Light blue, representing the sky
    "On Rails": "#f6f6f6",       # Dark orange, representing rails or transit
    "Bridge": "	#549aab",         # Saddle brown, representing wooden/earthy bridges
    "Pedestrian Area": "#f1802d" # Lime green, representing pedestrian-friendly zones
}
# Map the colors to the dominant object for plotting
BG_census_semantic_gdf["color"] = BG_census_semantic_gdf["dominant_object"].map(color_map)

# Plot the map with colors based on the dominant object
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_semantic_gdf.plot(ax=ax, color=BG_census_semantic_gdf["color"])

# Add legend for dominant objects
for obj, color in color_map.items():
    ax.plot([], [], color=color, label=obj)
ax.legend(title="Dominant Pixel Ratios of Object", loc="upper right", bbox_to_anchor=(1.3, 1))

ax.set_title("Dominant Pixel Ratios of Object by Block Group")
ax.axis("off")

plt.show()


# Plot the heatmap for Pedestrian Area
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_semantic_gdf.plot(
    ax=ax, 
    column="Pedestrian Area",  # Use the column for heatmap values
    cmap="Greens",             # Green colormap to represent pedestrian-friendly areas
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Pedestrian Area Ratio"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Pedestrian Area Ratios by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Pedestrian Area
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_semantic_gdf.plot(
    ax=ax, 
    column="Road",  # Use the column for heatmap values
    cmap="Blues",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Road Area Ratio"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Road Area Ratios by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Bike Lanes
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_semantic_gdf.plot(
    ax=ax, 
    column="Bike Lane",  # Use the column for heatmap values
    cmap="Purples",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Bike Lane Ratio"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Bike Lane Ratios by Block Group", fontsize=16)
ax.axis("off")

plt.show()



# Plot the heatmap for Pedestrian Area
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_semantic_gdf.plot(
    ax=ax, 
    column="Vegetation",  # Use the column for heatmap values
    cmap="Greens",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Vegetation Ratio"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Vegetation Area Ratios by Block Group", fontsize=16)
ax.axis("off")

plt.show()





import seaborn as sns
import matplotlib.pyplot as plt



# Identify the dominant object (column with the highest ratio) for each block group
corr_columns =BG_census_semantic_gdf.columns.difference(["ALAND20", "geometry", 'AWATER20',
                                                'BLKGRPCE20', "GEOID20", "block_group_id", 
                                                'TRACTCE20', 'COUNTYFP20', 'FUNCSTAT20', 
                                                "color", 'INTPTLAT20', 'INTPTLON20', 'NAMELSAD20', 
                                                 "WKT", 'block group', 'county', 
                                                'state', 'tract', 'MTFCC20','STATEFP20', 'dominant_object'])


# Filter the GeoDataFrame to these columns
correlation_data = BG_census_semantic_gdf[corr_columns]
# Compute the correlation matrix
correlation_matrix = correlation_data.corr()

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(
    correlation_matrix, 
    annot=False, 
    fmt=".2f", 
    cmap="coolwarm", 
    cbar=True,
    square=True
)
plt.title("Correlation Matrix of Objects and Census Data")
plt.show()



import seaborn as sns
import matplotlib.pyplot as plt

# Define a mapping from original column names to descriptive names
column_name_mapping = {
    "Road": "Road",
    "Sky": "Sky",
    "Pedestrian Area": "Pedestrian Area",
    "Vegetation": "Vegetation",
    "B19013_001E": "Median Household Income",
    "B01001_001E": "Total Population",
    "B08301_010E": "Public Transit Users"
}

# Select and rename the columns
smaller_corr_columns = ["Road", "Sky", "Pedestrian Area", "Vegetation", "B19013_001E", "B01001_001E", "B08301_010E"]
small_correlation_data = BG_census_semantic_gdf[smaller_corr_columns].rename(columns=column_name_mapping)

# Compute the correlation matrix
small_correlation_matrix = small_correlation_data.corr()

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(
    small_correlation_matrix, 
    annot=True, 
    fmt=".2f", 
    cmap="coolwarm", 
    cbar=True,
    square=True
)
plt.title("Correlation Matrix of Semantic Segmentation and Census Data", fontsize=16)
plt.show()






panoptic_mean_seg_pivot = mean_agg_labels.pivot(
    index="block_group_id",
    columns="label_name",
    values="avg_counts"
).reset_index()


panoptic_total_seg_pivot = sum_agg_labels.pivot(
    index="block_group_id",
    columns="label_name",
    values="total_counts"
).reset_index()

panoptic_mean_seg_pivot.head()


panoptic_total_seg_pivot.head()


# For total panoptic data 
BG50_gdf = BG50_gdf.copy()

# Ensure no issue with merging 
panoptic_total_seg_pivot.loc[:, 'block_group_id'] = panoptic_total_seg_pivot['block_group_id'].astype(str)
BG50_gdf.loc[:,'GEOID20'] = BG50_gdf['GEOID20'].astype(str)

# Merge census data with segmentation data
BG_census_panoptic_total_data = pd.merge(
    BG50_gdf, 
    panoptic_total_seg_pivot, 
    left_on="GEOID20", 
    right_on="block_group_id", 
    how="left"
)

BG_census_panoptic_total_data.head()


# For av count panoptic data 
BG50_gdf = BG50_gdf.copy()

# Ensure no issue with merging 
panoptic_mean_seg_pivot.loc[:, 'block_group_id'] = panoptic_mean_seg_pivot['block_group_id'].astype(str)
BG50_gdf.loc[:,'GEOID20'] = BG50_gdf['GEOID20'].astype(str)

# Merge census data with segmentation data
BG_census_panoptic_avg_data = pd.merge(
    BG50_gdf, 
    panoptic_mean_seg_pivot, 
    left_on="GEOID20", 
    right_on="block_group_id", 
    how="left"
)

BG_census_panoptic_avg_data.head()


# Create a new column for the dominant object
BG_census_panoptic_total_data["dominant_object"] = BG_census_panoptic_total_data[object_columns].idxmax(axis=1)
print(BG_census_panoptic_total_data["dominant_object"].unique())



# Create a color map for the dominant objects
unique_objects = BG_census_panoptic_total_data["dominant_object"].unique()
print(unique_objects)
# Define custom colors for dominant objects
panoptic_color_map = {
    "Car": "#549aab",         
    "Utility Pole": "#f1802d"  
}
# Map the colors to the dominant object for plotting
BG_census_panoptic_total_data["color"] = BG_census_panoptic_total_data["dominant_object"].map(panoptic_color_map)

# Plot the map with colors based on the dominant object
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_total_data.plot(ax=ax, color=BG_census_panoptic_total_data["color"])

# Add legend for dominant objects
for obj, color in panoptic_color_map.items():
    ax.plot([], [], color=color, label=obj)
ax.legend(title="Dominant Object Instances", loc="upper right", bbox_to_anchor=(1.3, 1))

ax.set_title("Dominant Object Instances by Block Group")
ax.axis("off")

plt.show()


# Plot the heatmap for Persons (Mean)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_avg_data.plot(
    ax=ax, 
    column="Person",  # Use the column for heatmap values
    cmap="Greens",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Persons Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Mean Persons Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Persons (Total)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_total_data.plot(
    ax=ax, 
    column="Person",  # Use the column for heatmap values
    cmap="Greens",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Persons Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Total Persons Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Cars (Mean)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_avg_data.plot(
    ax=ax, 
    column="Car",  # Use the column for heatmap values
    cmap="Blues",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Car Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Mean Car Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Persons (Total)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_total_data.plot(
    ax=ax, 
    column="Car",  # Use the column for heatmap values
    cmap="Blues",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Persons Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Total Cars Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Bicyclists (Mean)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_avg_data.plot(
    ax=ax, 
    column="Bicyclist",  # Use the column for heatmap values
    cmap="Purples",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Bicyclist Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Mean Bicyclist Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()




# Plot the heatmap for Persons (Total)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_total_data.plot(
    ax=ax, 
    column="Bicyclist",  # Use the column for heatmap values
    cmap="Purples",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Total Bicyclist Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Total Bicyclist Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()


# Plot the heatmap for Bicyclists (Mean)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_avg_data.plot(
    ax=ax, 
    column="Utility Pole",  # Use the column for heatmap values
    cmap="Blues",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Mean Utility Pole Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Mean Utility Pole Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()

# Plot the heatmap for Persons (Total)
fig, ax = plt.subplots(figsize=(12, 8))
BG_census_panoptic_total_data.plot(
    ax=ax, 
    column="Utility Pole",  # Use the column for heatmap values
    cmap="Blues",             
    legend=True,               # Show legend for the heatmap
    legend_kwds={"label": "Total Utility Pole Count"}
)

# Add map title and remove axis
ax.set_title("Heatmap of Total Utlity Pole Counts by Block Group", fontsize=16)
ax.axis("off")

plt.show()





import seaborn as sns
import matplotlib.pyplot as plt

# Define a mapping from original column names to descriptive names
column_name_mapping = {
    "Lane Marking - Crosswalk":"Crosswalk",
    "Sidewalk": "Sidewalk",
    "Utility Pole": "Utility Pole",
    "Car": "Car",
    "Person": "Person",
    "Vegetation": "Vegetation",
    "B19013_001E": "Median Household Income",
    "B01001_001E": "Total Population",
    "B08301_010E": "Public Transit Users"
}

# Select and rename the columns
smaller_corr_columns = ["Lane Marking - Crosswalk", "Sidewalk", "Utility Pole", "Car", "Person", "Vegetation", "B19013_001E", "B01001_001E", "B08301_010E"]
small_corr_panoptic_data = BG_census_panoptic_avg_data[smaller_corr_columns].rename(columns=column_name_mapping)

# Compute the correlation matrix
small_corr_panoptic_matrix = small_corr_panoptic_data.corr()

# Plot the correlation matrix as a heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(
    small_corr_panoptic_matrix, 
    annot=True, 
    fmt=".2f", 
    cmap="coolwarm", 
    cbar=True,
    square=True
)
plt.title("Correlation Matrix of Objects and Census Data", fontsize=16)
plt.show()



import pandas as pd
import geopandas as gpd
from shapely.geometry import Polygon

# Pivot segmentation data to create one column per object type
panoptic_segmentation_pivot = panoptic_data.pivot(
    index="block_group_id",
    columns="label_name",
    values="relative_ratios"
).reset_index()

# Make a copy of BG50 
BG50_gdf = BG50_gdf.copy()

# Ensure no issue with merging 
segmentation_pivot.loc[:, 'block_group_id'] = segmentation_pivot['block_group_id'].astype(str)
BG50_gdf.loc[:, 'GEOID20'] = BG50_gdf['GEOID20'].astype(str)

# Merge census data with segmentation data
BG_census_semantic_data = pd.merge(
    BG50_gdf, 
    segmentation_pivot, 
    left_on="GEOID20", 
    right_on="block_group_id", 
    how="left"
)

# Convert merged data into a GeoDataFrame
BG_census_semantic_gdf = gpd.GeoDataFrame(BG_census_semantic_data, geometry="geometry")

# Fill Nan values as 0 
BG_census_semantic_gdf = BG_census_semantic_gdf.fillna(0)
BG_census_semantic_gdf.head()


# Calculate relative proportions of object types within each block group
# First, compute total counts per block_group_id
total_counts_per_group = (
    aggregated_data.groupby('block_group_id')['total_counts'].sum().reset_index()
)
total_counts_per_group.rename(columns={'total_counts': 'group_total_counts'}, inplace=True)
total_counts_per_group.head()



# Merge total counts back into the aggregated data
aggregated_data = aggregated_data.merge(
    total_counts_per_group, on='block_group_id', how='left'
)

# Calculate proportions for each label_name within each block group
aggregated_data['relative_proportion'] = (
    aggregated_data['total_counts'] / aggregated_data['group_total_counts']
)
aggregated_data.head()


import matplotlib.pyplot as plt

# Plot dominant objects for block groups
plt.figure(figsize=(12, 6))
dominant_objects_sorted = dominant_objects.sort_values('total_counts', ascending=False)
plt.bar(dominant_objects_sorted['block_group_id'], dominant_objects_sorted['total_counts'])
plt.xlabel('Block Group ID')
plt.ylabel('Counts of Dominant Object')
plt.title('Dominant Object Counts by Block Group')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()



import seaborn as sns

# Create a pivot table for proportions
pivot_table = aggregated_data.pivot(
    index='block_group_id', columns='label_name', values='relative_proportion'
).fillna(0)

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(pivot_table, cmap='coolwarm', annot=False)
plt.title('Heatmap of Relative Proportions of Object Types by Block Group')
plt.xlabel('Object Types (Label Name)')
plt.ylabel('Block Group ID')
plt.show()



import numpy as np

# Step 1: Calculate proportions for each label_name in each block group
aggregated_data['relative_proportion'] = (
    aggregated_data['total_counts'] / aggregated_data['group_total_counts']
)

# Step 2: Define a function to compute the Shannon Diversity Index
def calculate_shannon_diversity(group):
    proportions = group['relative_proportion']
    return -np.sum(proportions * np.log(proportions))

# Step 3: Apply the function to each block group
diversity_index = (
    aggregated_data.groupby('block_group_id')
    .apply(calculate_shannon_diversity)
    .reset_index(name='shannon_diversity')
)

# Display the diversity index for each block group
print(diversity_index.head())
"""
# Save the results to a CSV file
diversity_index.to_csv('shannon_diversity_index.csv', index=False)
"""
# Bar plot of diversity index
plt.figure(figsize=(12, 6))
diversity_index_sorted = diversity_index.sort_values('shannon_diversity', ascending=False)
plt.bar(diversity_index_sorted['block_group_id'], diversity_index_sorted['shannon_diversity'], color='k')
plt.xlabel('Block Group ID')
plt.ylabel('Shannon Diversity Index')
plt.title('Shannon Diversity Index by Block Group')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()



# Function to compute Simpson's Diversity Index
def calculate_simpson_diversity(group):
    proportions = group['relative_proportion']
    return 1 - np.sum(proportions**2)

# Apply the function to each block group
simpson_diversity = (
    aggregated_data.groupby('block_group_id')
    .apply(calculate_simpson_diversity)
    .reset_index(name='simpson_diversity')
)

print(simpson_diversity.head())
# Bar plot of diversity index
plt.figure(figsize=(12, 6))
diversity_index_sorted = simpson_diversity.sort_values('simpson_diversity', ascending=False)
plt.bar(diversity_index_sorted['block_group_id'], diversity_index_sorted['simpson_diversity'], color = 'k')
plt.xlabel('Block Group ID')
plt.ylabel('Simpson Diversity Index')
plt.title('Simpson Diversity Index by Block Group')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()



# Save outputs if needed
dominant_objects.to_csv('dominant_objects_per_block_group.csv', index=False)
aggregated_data.to_csv('label_proportions_per_block_group.csv', index=False)

# Display results
print("Dominant Objects per Block Group:")
print(dominant_objects.head())

print("\nRelative Proportions of Labels in Each Block Group:")
print(aggregated_data.head())

